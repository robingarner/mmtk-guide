\chapter{Introduction}

This document is intended to be a comprehensive reference manual for MMTk, the Memory Management Toolkit.

The intended audience is anyone intending to create or modify an MMTk collector, and developers of
language runtimes/virtual machines who want to integrate MMTk into their system.
It attempts as far as possible not to pre-suppose any specialist knowledge of Memory Management, Java
Virtual Machines or Jikes RVM.
Conversely it does not attempt to be a comprehensive introduction to any of these subjects, and
readers are encouraged to read various other reference materials which do this task much more successfully.
Instead, I attempt to provide enough background information to understand the MMTk code in question,
providing a description of MMTk's algorithm or implementation and referring the reader to a more
comprehensive reference source for alternative approaches or broader descriptions of tradeoffs.

\section{Managed Runtimes and Virtual Machines}

The simplest programming languages, such as Assemblers, Bliss and early versions
of C provide little more than a conversion of code from a human-readable language
into machine instructions.  Richer languages such as modern versions of C, Modula-2
and Fortran also specify a ``standard library'' of functions and procedures that
provide commonly used code to improve programmer productivity.  Many commonly used
languages in the modern world come with a huge library of types and code, and have 
complex built-in features such as threads and synchronization and inter-thread
communication.

Most programming languages run on a variety of machine architectures with subtly
different memory semantics, byte ordering etc.  The simpler low-level languages
expose these differences to the programmer, so that the semantics of a program
can change depending on the machine on which it is running.  Other languages
provide an abstract machine specification to the programmer, requiring the compiler
and language runtime to abstract over the architectural differences in the
underlying machine.  In these language implementations it is common to refer
to the language runtime as a \emph{virtual machine}, and this is the terminology
used in \mmtk.

% About
%
% Intro to GC
\section{Automatic Memory Management}

Programming languages that support dynamic data structures require mechanisms for allocating memory,
and recovering it for re-allocation when it is no longer used.  Languages such as C require the programmer
to track memory usage and to explicitly free memory when it is no longer in use.  Languages such as LISP
and \java use automatic methods called \emph{garbage collection} to reclaim unused memory.  These languages
also support features such as \emph{finalizers} and \emph{reference types} that require support from the
garbage collector.

Freeing the programmer from the responsibility of freeing memory leads to a significantly different programming
style to manually managed languages. This leads to more frequent memory allocation, often of objects which
are very short lived.  The efficiency of memory allocation becomes a much more significant performance 
issue for languages with automatic memory management than it is in other languages.  This affects the way
MMTk is written, because saving a couple of instructions (particularly memory references) in an allocator
can have a significant performance effect.


\subsection{Allocation}

Allocation of memory is one of the two major functions of a memory manager.  There are
two basic methods: \emph{bump-pointer} or \emph{monotonic} allocation, where objects
are allocated from a contiguous region of memory by ``bumping a pointer''; and 
\emph{feee-list} allocation, where unused regions of memory are maintained in
a list.

For more information, the survey paper of \citet{WJNB:95} is a good starting place.
% Free List / Bump Pointer
% Unsync/sync

All of the MMTk allocators optimize performance by avoiding synchronization.  
Each allocator uses synchronized access to allocate a thread-local buffer from shared storage,
then allocates regions from the thread local structures without synchronization.  This
is a significant optimization.  Figure~\ref{fig:intro:thread-local-alloc} 
illustrates this pattern in  pseudo-code.

\begin{figure}
\begin{centering}
\begin{lstlisting}
Address alloc(bytes) {
  if (!localBuffer.available(bytes)) {
    localBuffer.install(allocSharedBlock());
  }
  return localBuffer.alloc(bytes);
}
Address allocSharedBlock() {
  lock();
  Address result = sharedPool.allocBlock();
  unlock();
  return result;
}
\end{lstlisting}
\end{centering}
\caption{Thread-local allocation}
\label{fig:intro:thread-local-alloc}
\end{figure}


\subsubsection{Bump-pointer Allocation}

Bump-pointer allocation uses a contiguous region of memory, satisfying each allocation
request by allocating the next $n$ bytes of the buffer.  Figure~\ref{fig:intro:bump-pointer}
illustrates this in pseudo-code.  

\begin{figure}[h!]
\begin{centering}
\begin{lstlisting}
Address alloc(bytes) {
  if (cursor+bytes > limit) {
    cursor = allocSharedBlock();
    limit = cursor + BLOCK_SIZE;
  }
  Address result = cursor;
  cursor += bytes;
  return result;
}
\end{lstlisting}
\end{centering}
\caption{Bump-pointer allocation}
\label{fig:intro:bump-pointer}
\end{figure}

In MMTk, bump-pointer allocation is used in spaces that copy objects during collection.  
It is almost never used outside of garbage collected memory managers.  The simplest example
of bump-pointer allocation is in the semi-space collector, where memory is divided into halves,
and when a garbage collection is performed, all objects are copied into the empty half of memory.

\subsubsection{Free-list Allocation}

Free list allocation is a widely used technique.  Free space is maintained in one or more lists,
and allocation consists of locating the head of the appropriate list and updating the head to point
to the next block in the list.\footnote{More complex free lists with variable length lists are used, but not in MMTk}
If the list is empty, a block of memory is allocated from the shared pool, broken into blocks
with a free list structure and installed at the head of the list.  Figure~\ref{fig:intro:free-list}
illustrates this in pseudo-code.  This algorithm is known as a ``segregated free-list''.

\begin{figure}[h!]
\begin{lstlisting}
Address alloc(bytes) {
  int sizeClass = getListFor(bytes);
  if (listHead[sizeClass] == null) {
    Address block = allocSharedBlock();
    createFreeList(block, sizeClass);
    listHead = firstCell(block);
  }
  Address result = listHead[sizeClass];
  listHead[sizeClass] = nextCell(result);
  return result;
}
\end{lstlisting}
\caption{Free-list allocation}
\label{fig:intro:free-list}
\end{figure}

Free-list allocation is generally less efficient than bump-pointer allocation, but has the advantage
that free cells can be re-used without copying.  The simplest example of this is the mark-sweep 
collector, which uses a mark bit to determine which objects are alive.  In the method 
\lstinline|createFreeList(\ldots)|, the mark bits are checked, and cells which contain live
objects are left out of the free list.

\subsubsection{Large Objects}

One limitation of a Segregated Free-list allocator is that there are necessarily a limited number of 
cell sizes, and therefore a maximum object size that can be allocated.  While a bump-pointer allocator
can handle arbitrarily large objects, copying large objects tends to be inefficient.  MMTk uses
a specialized allocator for handling large objects, generally objects larger than 8KB.  This
is a free-list allocator designed for objects of varying sizes.
The first time a large object is allocated, one or more 4MB chunks of memory are reserved,
and a data structure is created at the start of the chunk to track the free space in the chunk.
This allocator allocates one or more 4KB pages per object, and tracks the pages in use using the
per-chunk data structure.
At collection time, the algorithm used is Baker's Treadmill~\cite{Baker:92}, which I will describe
in more detail in Section~\ref{sec:policy:LargeObject}.  This is a non-copying collector, designed
specifically for large objects.

\subsection{Garbage Collection}

Garbage collection is the process of identifying the objects that are no longer in use and 
recycling it for future allocation.  The literature on the subject is extensive, going back to
the original Lisp system in 1960.

All garbage collectors use the process of \emph{tracing} to identify the relationships between 
objects.  Tracing is an iterative process, and each step involves taking an object, 
performing some operation on it, identifying
which fields in the object contain \emph{references} to other objects, and possibly repeating 
the tracing process for each object that is referenced.  The operation performed and the criteria
for choosing which references are followed depends on the garbage collection algorithm being 
implemented.  Concrete examples of tracing will be given below.

Following \citet{DLM+:76}, garbage collection literature divides the threads in a multi-threaded
system into \emph{mutator} threads and \emph{collector} threads.  The mutator threads perform the actual
work of the running program, but from the point of view of the garbage collector, they do two
things: allocate objects and change the values of their fields.

All of the collectors implemented in MMTk rely on the host virtual machine to identify the 
reference fields in objects in the heap.  MMTk also relies on the virtual machine to track the
\emph{root set}, those locations outside the heap that contain references into the heap.  In 
the Java language the root set consists of the static fields of loaded classes,  
locations in the thread stacks that contain references (including local variables), and certain
fields in data structures maintained by the virtual machine itself.

\subsubsection{Marking}

Several collection algorithms use a process of \emph{marking} the heap to identify the live
objects.  The classic mark-sweep collector~\citep{McCarthy:60} allows LISP code to execute until
the system runs out of memory.  Then the system traces the heap, starting from the root set,
setting a bit in the the header of each object it finds.  The algorithm maintains a stack of
objects that have not yet been visited.  When tracing an object, the collector examines the mark 
bit of each referenced object.  If the bit is not yet set, the collector sets it and pushes the 
object's address onto the stack.  Of the bit is already set, no further action is taken. 
The algorithm then pops the next object from the stack, repeating the process until the stack
is empty (Figure~\ref{fig:intro:mark}).
Mathematically, this process performs a \emph{transitive closure} over the set of objects that
are reachable from the roots.  Any object that does not have its mark bit set at the end of this
process, known as the \emph{mark phase} can never be reached by the runn ing program, and is
free to be re-allocated.  In the classic mark-sweep collector, the \emph{sweep phase} scans all
objects in the heap, places unmarked objects onto the free list, and clears the mark bit of all 
marked objects.

\begin{figure}[h!t]
\begin{lstlisting}
void mark() {
  for (root in rootSet) {
    if (!testAndMark(root)) 
      stack.push(root);
  }
  while (not stack.isEmpty()) {
    Object obj = stack.pop();
    for (child in references(obj))
      if (!testAndMark(child)) 
        stack.push(child);
  }
}
\end{lstlisting}
\caption{Classic mark-sweep collection}
\label{fig:intro:mark}
\end{figure}

\subsubsection{Copying}

A large class of garbage collectors copy live objects into new locations.  The canonical example
of this is the semi-space collector mentioned briefly above.  This collector divides memory into
two equal parts or \emph{spaces}, which we refer to as \emph{from-space} and \emph{to-space}.  
Initially objects are allocated into to-space using a bump-pointer, until it is full and a 
garbage collection begins.  At the start of the collection, we rename the spaces, the empty one 
becoming to-space.  As with mark-sweep, we start to trace the heap beginning with the roots.  
Each time we visit an object, we check its header.  If it has not yet been visited, we allocate 
a region in to-space, copy the contents of the object, and write the new address of the copy
of the object somewhere in the old object (the \emph{forwarding pointer}).  Then we update the field that pointed to this
object to have the object's new address.  If the object has already been visited, we retrieve
the forwarding pointer and update the reference that led us here.  At the end of the collection, all
live objects now occupy space in the (new) to-space, and all reference fields have been updated
with the new addresses of the objects (Figure~\ref{fig:intro:semi-space}).

\begin{figure}[h!t]
\begin{lstlisting}
void collect() {
  for (Address root in rootSet) {
    root.store(trace(root.load());
  }
  while (not stack.isEmpty()) {
    Object obj = stack.pop();
    scan(obj);
  }
}

ObjectReference trace(ObjectReference obj) {
  if (moved(obj)) {
    return forwardingAddress(obj);
  } else {
    Address newAddr = allocCopy(obj);
    copy(obj.toAddress(), newAddr);
    return newAddr.toObjectReference();
  }
}
\end{lstlisting}
\caption{Classic semi-space collection}
\label{fig:intro:semi-space}
\end{figure}

The key advantage of copying collection (particularly with a depth-first traversal) is
that linked objects are co-located in from-space.  This improves mutator locality through
reduced cache misses.  Garbage collector throughput is lower than with a non-copying collector.

% Tracing
% - Copying (evacuating)
% - In-place
% Reference Counting

\subsubsection{Reference Counting}

\begin{quotation}
One day a student came to Moon and said: ``I understand how to make a better garbage collector. 
We must keep a reference count of the pointers to each cons.''

Moon patiently told the student the following story:

``One day a student came to Moon and said: `I understand how to make a better garbage collector\ldots' ''
\end{quotation}

Among programmers who have not studied garbage collection, reference counting is the most
popular algorithm.  It has an intuitive attraction but suffers from two significant drawbacks.
Firstly, the operation of maintaining the reference count is expensive.  Every pointer write
requires an additional load and synchronized store operation.  The second drawback
is that reference counting alone cannot collect cyclic data structures and requires
a backup collector.

The reference counting implementation in MMTk avoids this overhead by using
\emph{deferred reference counting} which records increments and decrements
in a buffer, periodically flushing the buffers and updating the reference counts
in the heap.  Reference count updates from stack variables are only performed
during these collections, further reducing the frequency of updates.

The reference counting implementation in MMTk is highly optimized, and is
competitive with MMTk's other collectors~\citep{SBF:12}.  Reference counting
is the most complex of the collectors in MMTk.

\subsubsection{Generational Collection}

Most benchmarks allocate a large number of objects with very short lifetimes.
Conversely, objects that have survived several garbage collections are statistically
likely to survive the next collection.  Generational collection takes advantage of
these observations by allocating new objects into one section of the heap and
collecting this region more frequently than the rest of the heap.  We refer to
the area where new objects are allocated as the \emph{nursery} (known in the Sun
virtual machine as the \emph{eden} space).  The area where survivors of the
nursery collection (also known as a \emph{minor collection}) is known as
the \emph{mature space}, and a collection of the mature space is known as
a \emph{major collection} or a \emph{full-heap} collection.

The simplest generational implementation uses a copying nursery.  Survivors of 
a nursery collection are copied to the mature space, and a variety of collection
methods are used.  In general, each collection policy has a generational counterpart.

Generational collection does not necessarily require copying, and can be implemented
within the same space.  In \mmtk this is done with \emph{sticky mark bits}~\citep{Demers:1989}
in the collectors \lstinline|StickyImmix| and \lstinline|StickyMS|.

The key characteristic of generational collection is that they collect a subset
of the heap.  In order to achieve this they rely on a \emph{write barrier}, \ie a
piece of code that executes whenever a pointer field of a heap object is modified.
The generational write barrier examines the addresses of the source and target objects,
and if it points from outside the nursery to an object inside the nursery, the
address either of the source object or the source field is recorded in a buffer
known as the \emph{remembered set} or \emph{remset}.
During a minor collection the remembered set is used as an additional source of roots
into the nursery, allowing the collector to identfy live objects in the nursery
without tracing the rest of the heap.

\subsection{Language Features}

Modern programming languages offer features that are implemented by or in 
conjunction with the garbage collector.  There are also some features that 
while not implemented directly by the GC have an influence on its design.

\subsubsection{Reference Types}

Many languages (including Java, Haskell and C\#) define \emph{reference types}, which
allow the mutator to keep a reference to an object without this reference keeping
the referent alive.  The exact semantics of these reference types varies according
to the language, and \mmtk provides methods in its Virtual Machine interface that
facilitate the implementation of these features.  

In \java, the language provides classes in the package 
\lstinline|java.lang.reference|
which implement the appropriate semantics.  The constructors of the reference
objects take an object as a parameter (the \emph{referent}, 
and provide a \lstinline|get()| method
that will either return the referent or \lstinline|null| as specified by
the semantics of the reference type.
All reference types in \java allow the creator to request that the reference will
be added to a queue when the referent becomes unreachable, allowing the program
to (for example) release operating system resources such as file handles.
Here is a brief outline of the semantics of the Java reference types.

\emph{Soft References} allow the mutator to access the referent, but if the
garbage collector detects an out-of-memory situation it is allowed to reclaim
the referent.  This is designed to implement performance optimizations such as 
caching when memory is plentiful, falling back to slower uncached access when 
the heap is close to full.

\emph{Weak References} also allow the mutator to access the referent, but only
when the referent is strongly reachable via another path.  This allows optimizations
such as {interning}, where rather than allocating a large number of identical 
objects, multiple references to identical objects can be shared.  A common way to
implement this is by creating a hash map of the extant objects and consulting the
hash map before creating a new value.  Without any form of weak reference (or
complex manual memory management) this approach can leak memory since every value
ever created will live until removed from the tables.  A hash table implemented
with weak references will only retain those values that are reachable from 
other data structures.

\emph{Phantom References} are the weakest of the reference types, and don't actually
allow the mutator to access the referenced object.  The only useful function of a
phantom reference is that it is enqueued to a reference queue when its referent
becomes unreachable.

In order to maintain its language independence, \mmtk leaves the implementation of
reference types to the host virtual machine, but nonetheless it requires that the
appropriate handlers that the VM provides are called at the correct stage of 
garbage collection.

\subsubsection{Finalizers}

Finalization is similar to reference types in that it requires some action to
be taken when the garbage collector determines that an object has become 
unreachable.  Unlike reference types, finalization requires that the objects themselves
be ``revived'', and their finalization method executed.  As with reference types,
finalizers are implemented in the host virtual machine, but their existence places
constraints on the structure of \mmtk plans.

\subsubsection{Hashing}

All Java objects provide a \lstinline|hashCode()| method, which (if not overridden 
by the programmer) is commonly implemented as a function of the address of the 
object.  This poses an issue for memory managers based on hashing.  The approach 
taken by \jikes is that the first time \lstinline|hashCode()| is invoked on an object,
a bit in the object header is set to record the fact.  If the garbage collector
subsequently moves the object to another address, an additional word of memory is allocated
either before the first word of the header or after the last word of the object,
and the initial address of the object when it was first hashed is saved in this
word.  Once this has taken place, a second bit in the header is set to indicate that
future \lstinline|hashCode()| operations should fetch the original hash value from the heap\
rather than using the object address.

MMTk does not implement any specific hashcode scheme, but allowing for this feature
influences the design of the MMTk to Virtual Machine interface.

% Intro to MMTk
\section{MMTk}

The design of \mmtk is described in depth by \citet{BCM:04, BCM:04b}.
The key aims are to provide a toolkit for building high performance 
memory managers, without sacrificing desirable software engineering
qualities like abstraction, code re-use and modularity.  As a research tool, \mmtk aims
to provide high performance implementations of the major garbage collection algorithms
so that researchers can evaluate their performance across new hardware environments,
and new algorithms can be evaluated against existing algorithms.

Some of the key engineering concerns from a performance point of view are:
\begin{itemize}
  \item Fast allocation.  
  \item Fast read and write barriers.
  \item High throughput collection.
\end{itemize}
Achieving the highest performance without sacrificing modularity is achieved by rigorously
differentiating between the frequently executed code (the \emph{fast path}) and less frequently
(\emph{slow path}) code.

All \mmtk collectors are \emph{parallel}, meaning that the work of the most time-consuming 
steps are performed by several threads in parallel.  Most of the \mmtk collectors are 
\emph{stop the world} collectors, so that during collection the mutators are suspended.  At time
of writing there is one concurrent collector in the MMTk distribution, in which one or more
collection threads run concurrently with the mutator.  This collector periodically stops all the
mutator threads, but for a much shorter time than in the stop-the-world collectors.

MMTk is best approached by understanding some of its design patterns and abstractions.

\subsection{Design Patterns}

MMTk's design patterns are described by \citet{BCM:04}, summarized briefly here.  

The most pervasive pattern is \emph{hot and cold paths}, where frequently executed code
(the \emph{hot path} or \emph{fast path}) is implemented using efficient, lightweight, unsynchronized 
mechanisms, periodically calling more heavyweight mechanisms (the \emph{cold path} or \emph{slow path}).
The hot and cold paths are generally implemented as separate methods, and often in separate
classes.

The \emph{local and global scopes} pattern works hand-in-hand with the hot and cold paths pattern.
All of the high performance data structures use unsynchronized objects that are dedicated to 
a single thread, and which share access to a single global object whose methods are synchronized.
This is the pattern used in the thread-local allocation example shown earlier 
(Figure~\ref{fig:intro:thread-local-alloc}), and is pervasive through \mmtk.  The unsynchronized
fast-path code is implemented in a thread-local \lstinline|Allocator| class, and the global
pool of blocks and the slow-path code is managed by a global \lstinline|Space| class.

\subsection{Plans}
\label{sec:intro:plans}

In \mmtk, a \emph{plan} is a complete memory manager for a virtual
machine.  While MMTk provides many plans, a running virtual machine
may only use one plan to manage its memory requirements.  

A plan consists of five or more classes which inherit from certain
abstract superclasses common to all plans.  
The components of a plan are described briefly in figure~\ref{fig:intro:plan}.

\begin{figure}
\begin{tabular}{|l|p{9cm}|}
\hline
Base class & Purpose \\
\hline
\multirow{3}{*}{\lstinline|Plan|} & Layout of virtual memory  \\
& Global policy objects \\
& Single-threaded collector phases \\ \hline
\multirow{3}{*}{\lstinline|MutatorContext|}  & Code executed directly by the Mutator threads \\
& Thread-local data structures required by Mutator threads \\
& Collector code executed on behalf of mutator threads \\ \hline
\multirow{3}{*}{\lstinline|CollectorContext|} & Memory allocation by collector threads \\
& Thread-local data structures required by Collector threads \\ 
& Collector code executed in parallel \\ \hline
\lstinline|PlanConstraints|  & Constants required by the virtual machine \\ \hline
\lstinline|TraceLocal| & The mechanics of tracing the heap.  Each type of collection
(eg nursery and full-heap) uses a separate TraceLocal class.  \\ \hline
\end{tabular}
\caption{Components of an \mmtk plan}
\label{fig:intro:plan}
\end{figure}

The Plan class is instantiated as a singleton.  Each running mutator thread must
have a unique MutatorContext object. In versions of Jikes RVM a Thread object is
a superclass of MutatorContext.  Each collector thread has its own CollectorContext object, and its own TraceLocal object.  More detail on these classes is provided in Chapter~\ref{chap:plan}.
%
% - Key concepts (policy, plan, local/global)
% 

\subsection{Virtual machine interfaces}

\mmtk aims to be independent of the virtual machine in which it runs.  It has
been used to implement garbage collection for several different languages,
and in at least three \java virtual machines.  In order to achieve this, it has
a well defined interface to the virtual machine in which it runs.  

The virtual machine interface consists of a package, \lstinline|org.mmtk.vm|,
containing a set of abstract classes.  The host virtual machine provides
implementations of these classes, and a factory object which \mmtk uses to
create instances of the interface classes at initialization time.

\mmtk also interfaces directly with raw memory, using a technique known as \emph{magic} \citep{FBC+:09}.
MMTk relies on extensions to the \java compiler to implement classes such as the 
\lstinline|org.vmmagic.unboxed.Address| class as \emph{unboxed} types of the same size as the natural
word length of the underlying machine.  The term \emph{unboxed} means that the object is stored
like a primitive type (an int or a long), and yet it has methods like an object (such as \lstinline|load()| and 
\lstinline|store(...)|).  Unboxed types have several limitations:
\begin{itemize}
  \item They only exist as local variables or fields of other objects, \ie you
  cannot perform a \lstinline|new| operation on an unboxed type.
  \item They cannot be cast to \lstinline|Object|.
\end{itemize}
The \todo{Add more here}
